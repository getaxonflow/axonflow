# AxonFlow Local Development Environment Variables
# Copy this file to .env and fill in your API keys

# LLM API Keys (optional for local development)
# Only needed if testing LLM integrations
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=

# Azure OpenAI Configuration
# Supports both Classic and Foundry patterns:
#   - Classic: endpoint=https://yourresource.openai.azure.com (uses api-key header)
#   - Foundry: endpoint=https://yourresource.cognitiveservices.azure.com (uses Bearer token)
# Auth type is auto-detected from endpoint URL
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_DEPLOYMENT_NAME=
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# Local LLM Endpoint (optional)
# If running a local LLM (e.g., Ollama, LM Studio)
OLLAMA_ENDPOINT=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.1:latest
LOCAL_LLM_ENDPOINT=

# Database settings are configured in docker-compose.yml
# No need to set them here unless you're using external PostgreSQL
